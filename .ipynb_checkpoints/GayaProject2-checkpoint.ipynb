{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Name: Mahesh Gaya\n",
    "Class: Machine Learning Fall 2016\n",
    "'''\n",
    "import pandas\n",
    "import random\n",
    "import math\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "#the class with functions to be used as entry points when\n",
    "#either training (fit) or predicting (predict) with the\n",
    "#decision tree algorithm\n",
    "class DTree:\n",
    "    def fit(self,predictor_columns_data,target_column_data):\n",
    "        self.__root_node = DNode(predictor_columns_data,target_column_data)\n",
    "        self.__root_node.train()\n",
    "        \n",
    "    def predict(self,df_of_new_examples):\n",
    "        #apply the predict function to the whole series, one at a time, this returns the series with the return vals\n",
    "        predictions = df_of_new_examples.apply(self.__root_node.predict,axis=1)\n",
    "        return predictions\n",
    "        \n",
    "    def print_tree(self):\n",
    "        self.__root_node.print_node()\n",
    "        \n",
    "\n",
    "#A class for representing non-leaf nodes in the decision tree\n",
    "class DNode:\n",
    "    \n",
    "    #when we create this node, we pass it training examples to be used at this point\n",
    "    #the predictor columns of these training examples is in predictor_columns_data\n",
    "    #the corresponding target values to those predictor columns are in target_column_data\n",
    "    def __init__(self,predictor_columns_data,target_column_data):\n",
    "\n",
    "        self.__attribute = ''  #the attribute used to sort examples at this node\n",
    "        self.__predictor_columns = predictor_columns_data #the training examples that have been sorted to this node\n",
    "        self.__target_column = target_column_data #the corresponding target values for the training examples\n",
    "        self.__child_nodes = {} #dictionary of the child nodes of this node, indexed by the value they have for self.__attribute\n",
    "        self.__most_common_value_here = '' #for keeping track of which target value is most common among the examples at this node. This is used to make a decision when there's no appropriate child node to follow\n",
    "        \n",
    "    #this should use the training data to determine the best attribute to use\n",
    "    #as is, it just chooses one at random, but you will fix it to use information gain\n",
    "    def choose_attribute(self):\n",
    "        #TODO: Add code for this\n",
    "        '''\n",
    "        Check entropy for each column, keep in list\n",
    "        Get the information gain, keep in list\n",
    "        Choose the best one\n",
    "        '''\n",
    "        # entropy = Sum(-pi * math.log(pi, 2))\n",
    "        print(\"Choose_attribute\")\n",
    "        entropy = []\n",
    "        for attribute in self.__predictor_columns.columns.values:\n",
    "            #Calculate entropy for each attribute, put that in a 2-d list\n",
    "            #Calculate the Expected entropy and Information gain for each\n",
    "            #Keep a variable for the best information gain\n",
    "            #Select the best one\n",
    "            \n",
    "            print(attribute) #Logging\n",
    "            #Initialize\n",
    "            #Get all the unique attributes of the column\n",
    "            unique_values = self.__predictor_columns[attribute].unique()\n",
    "            print(unique_values) #Logging\n",
    "            \n",
    "            #total count per unique attribute\n",
    "            count_per_unique_value = self.__predictor_columns[attribute].value_counts()\n",
    "            print(count_per_unique_value) #Logging\n",
    "            \n",
    "            #get number of Good(1) or Bad(2) for each attribute  '\n",
    "            #self.__predictor_columns.groupby(attribute).get_group(unique_value).get_value(row)\n",
    "            print(\"Train_data\")\n",
    "            good_bad = []\n",
    "            for unique_value in unique_values:\n",
    "                good_bad.append(train_data[train_data[attribute] == unique_value].value_counts())\n",
    "                \n",
    "                \n",
    "                    \n",
    "            #Deprecated\n",
    "            '''\n",
    "            total_count = self.__predictor_columns[attribute].count()\n",
    "            print(total_count) #Logging\n",
    "            proportion_per_unique_value = [] # make a copy\n",
    "            entropy = 0\n",
    "            print(proportion_per_unique_value)\n",
    "            for i in range(len(count_per_unique_value)):\n",
    "                proportion_per_unique_value.append(count_per_unique_value[i]/total_count)\n",
    "                entropy = - proportion_per_unique_value[i] * math.log(proportion_per_unique_value[i])\n",
    "            print(\"entropy: \" + str(entropy))\n",
    "            print(proportion_per_unique_value)\n",
    "            '''\n",
    "            \n",
    "            \n",
    "                \n",
    "                \n",
    "        self.__attribute = random.choice(self.__predictor_columns.columns.values) #what a terrible way to choose the attribute!\n",
    "        \n",
    "    #calling this will continue building the tree from this node given its training examples\n",
    "    def train(self):\n",
    "        self.choose_attribute() #'best' attribute at this node\n",
    "        \n",
    "        #in case we need to make a decision here because we don't have any children with a particular attribute value    \n",
    "        self.__most_common_value_here = self.__target_column.value_counts().idxmax()\n",
    "        \n",
    "        #gets all the values that these examples have in our chosen column\n",
    "        attribute_values_here = self.__predictor_columns[self.__attribute].unique()\n",
    "\n",
    "        #going through all possible values this attribute can have\n",
    "        #and creating the appropriate child node\n",
    "        for value in attribute_values_here: \n",
    "             \n",
    "            #the subset of examples with the given value\n",
    "            examples_for_child_predictor_cols = self.__predictor_columns[self.__predictor_columns[self.__attribute] == value] \n",
    "            examples_for_child_target_col = self.__target_column[self.__predictor_columns[self.__attribute] == value] #target values corresponding to the subset of examples with the given value\n",
    "            \n",
    "            #we grabbed the values from the examples themselves, so there should\n",
    "            #be at least one example that has each value, but just in case there isn't\n",
    "            #I don't want to crash the program\n",
    "            if examples_for_child_target_col.empty:\n",
    "                print(\"error: we shouldn't get here\")\n",
    "                \n",
    "            #there are no columns left to use for decisions at the child\n",
    "            #so lets make a leage node based on the most common target value in those examples\n",
    "            elif len(examples_for_child_predictor_cols.columns.values) == 1:  \n",
    "                #create a child with the most common target value here\n",
    "                leaf_child = DLeaf( self.__most_common_value_here )\n",
    "                self.__child_nodes[value] = leaf_child\n",
    "                \n",
    "            #if all child examples have the same target value, we make a leaf node\n",
    "            elif len(examples_for_child_target_col.unique()) == 1: #all child examples have same class\n",
    "                leaf_child = DLeaf( examples_for_child_target_col.unique()[0] ) #make leaf with that class\n",
    "                self.__child_nodes[value] = leaf_child #put the leaf in the dictionary of children nodes\n",
    "                \n",
    "            else: #we have a regular decision node for this attribute value\n",
    "                #get rid of the column for this attribute so it can't be selected again\n",
    "                examples_for_child_predictor_cols = examples_for_child_predictor_cols.drop(self.__attribute,1) \n",
    "                \n",
    "                new_child = DNode(examples_for_child_predictor_cols,examples_for_child_target_col)\n",
    "                new_child.train() #generate the rest of the subtree for this child\n",
    "                self.__child_nodes[value] = new_child #put the new child node in the dictionary of children nodes\n",
    "            \n",
    "\n",
    "    #print out the tree - not the prettiest, but you can see it.\n",
    "    def print_node(self,num_indents = 0):\n",
    "        for i in range(num_indents): \n",
    "            print(\" \",end=''), #print with no newline\n",
    "        print(self.__attribute)\n",
    "        for attr in self.__child_nodes.keys():\n",
    "            for i in range(num_indents): \n",
    "                print(\"|\", end='')\n",
    "            print(\":\"+attr)\n",
    "            self.__child_nodes[attr].print_node(num_indents+1)\n",
    "            \n",
    "    #make a prediction for a single new example\n",
    "    #this only makes sense to call after the tree has been build (with train())\n",
    "    def predict(self,new_example):\n",
    "        #look up the right branch in our dictionary of children\n",
    "        if new_example[self.__attribute] in self.__child_nodes:\n",
    "            node_on_corresponding_branch = self.__child_nodes[new_example[self.__attribute]]\n",
    "            return node_on_corresponding_branch.predict(new_example) #recursively call predict on the child node\n",
    "        else:\n",
    "            return self.__most_common_value_here #there was no child, so we predict the most common class of the examples at this node\n",
    "        \n",
    "#class for representing a leaf node in the tree\n",
    "class DLeaf:\n",
    "    \n",
    "    #when we create the node, all we need to know is what we're going to predict if we get here\n",
    "    def __init__(self,val_in_target_col):\n",
    "        self.__target_value = val_in_target_col\n",
    "    \n",
    "    #just returns the prediction for a new example, \n",
    "    #this was probably called from predict() of a regular node one level up in the tree\n",
    "    def predict(self,new_example):\n",
    "        return self.__target_value\n",
    "    \n",
    "    #for displaying the tree\n",
    "    def print_node(self,num_indents = 0):\n",
    "        for i in range(num_indents): \n",
    "            print(\" \",end='')\n",
    "        print(\"LEAF:\",self.__target_value)\n",
    "        \n",
    "    \n",
    "#simply compares two Pandas series and returns the proportion that match\n",
    "#this can be used to compute the accuracy of the prediction list against\n",
    "#the actual target column\n",
    "def accuracy(series1, series2):\n",
    "    correct = 0.0\n",
    "    for index, value in series1.iteritems():\n",
    "        if value == series2.loc[index]:\n",
    "            correct += 1\n",
    "    return (correct/len(series1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "credit_data = pandas.read_csv('german_credit.csv')\n",
    "print(credit_data['Duration in month'])\n",
    "plt.hist(credit_data['Duration in month'], [0,12,24,36,72])\n",
    "plt.xlabel('Duration in month')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()\n",
    "'''\n",
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "credit_data = pandas.read_csv('german_credit.csv')\n",
    "train_data, test_data = \\\n",
    "cross_validation.train_test_split(credit_data,test_size = 0.1)\n",
    "attributes_to_use = ['Status of existing checking account',\\\n",
    "        'Credit history','Purpose', 'Savings account/bonds', \\\n",
    "        'Present employment since', 'Personal status and sex', \\\n",
    "        'Other debtors / guarantors', 'Property', \\\n",
    "        'Other installment plans', 'Housing', \\\n",
    "        'Job', 'Telephone', 'foreign worker']\n",
    "my_tree = DTree()\n",
    "my_tree.fit(train_data[attributes_to_use],train_data['Creditability'])\n",
    "my_tree.print_tree()\n",
    "predictions = my_tree.predict(test_data[attributes_to_use])\n",
    "print(accuracy(test_data['Creditability'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJECTIVE: Predict Creditability\n",
    "##### Columns:\n",
    "1. Status of existing checking account\n",
    "\n",
    "    ```\n",
    "        A11 (...< 0 DM), \n",
    "        A12(0<=...<200 DM), \n",
    "        A13 (...>=200 DM), \n",
    "        A14(No checking)\n",
    "    ```\n",
    "\n",
    "2. Duration in month\n",
    "\n",
    "    ```\n",
    "        Numerical\n",
    "    ```\n",
    "\n",
    "3. Credit History\n",
    "\n",
    "    ```\n",
    "        A30 (no credits taken/all credits paid back duly), \n",
    "        A31 (all credits at this bank paid back duly), \n",
    "        A32 (existing credits paid back duly till now), \n",
    "        A33 (delay in paying off in the past\n",
    "        A34 (critical account/other credits existing (not at this bank)\n",
    "    ```\n",
    "\n",
    "4. Purpose\n",
    "\n",
    "    ```\n",
    "        A40 (car - new)\n",
    "        A41 (car - used)\n",
    "        A42 (furniture/equipment)\n",
    "        A43 (radio/television)\n",
    "        A44 (domestic appliances)\n",
    "        A45 (repairs)\n",
    "        A46 (education)\n",
    "        A47 (vacation - does not exist?)\n",
    "        A48 (retraining)\n",
    "        A49 (business)\n",
    "        A410 (others)\n",
    "    ```\n",
    "\n",
    "5. Credit amount\n",
    "\n",
    "    ```\n",
    "        Numerical\n",
    "    ```\n",
    "\n",
    "6. Savings account/bonds\n",
    "\n",
    "    ```\n",
    "        A61 (...<100 DM)\n",
    "        A62 (100 <= ... < 500 DM)\n",
    "        A63 (500 <= ... < 1000 DM)\n",
    "        A64 (...>= 1000 DM)\n",
    "        A65 (unknown/no savings account)\n",
    "    ```\n",
    "\n",
    "7. Present employment since\n",
    "\n",
    "    ```\n",
    "        A71 (unemployed)\n",
    "        A72 (...< 1year)\n",
    "        A73 (1 <= ... < 4 years)\n",
    "        A74 (4 <= ... < 7 years)\n",
    "        A75 (...>= 7 years)\n",
    "    ```\n",
    "\n",
    "8. Installment rate in percentage of disposable income\n",
    "\n",
    "    ```\n",
    "        Numerical\n",
    "    ```\n",
    "\n",
    "9. Personal status and sex\n",
    "\n",
    "    ```\n",
    "        A91 (male - divorced/separated)\n",
    "        A92 (female - divorced/separated/married)\n",
    "        A93 (male - single)\n",
    "        A94 (male - married/widowed)\n",
    "        A95 (female - single)\n",
    "    ```\n",
    "\n",
    "10. Other debtors / guarantors\n",
    "\n",
    "    ```\n",
    "        A101 (none)\n",
    "        A102 (co-applicant)\n",
    "        A103 (guarantor)\n",
    "    ```\n",
    "\n",
    "11. Present residence since\n",
    "\n",
    "    ```\n",
    "        Numerical\n",
    "    ```\n",
    "\n",
    "12. Property\n",
    "\n",
    "    ```\n",
    "        A121 (real estate)\n",
    "        A122 (if not A121 - building society savings agreement/life insurance)\n",
    "        A123 (if not A121/A122 - car or other, not in attribute 6)\n",
    "        A124 (unknown/no property)\n",
    "    ```\n",
    "\n",
    "13. Age in years\n",
    "\n",
    "    ```\n",
    "        Numerical\n",
    "    ```\n",
    "\n",
    "14. Other installment plans\n",
    "\n",
    "    ```\n",
    "        A141 (bank)\n",
    "        A142 (stores)\n",
    "        A143 (none)\n",
    "    ```\n",
    "15. Housing\n",
    "\n",
    "    ```\n",
    "        A151 (rent)\n",
    "        A152 (own)\n",
    "        A153 (for free)\n",
    "    ```\n",
    "\n",
    "16. Number of existing credits at this bank\n",
    "\n",
    "    ```\n",
    "        Numerical\n",
    "    ```\n",
    "\n",
    "17. Job\n",
    "\n",
    "    ```\n",
    "        A171 (unemployed/ unskilled - non-resident)\n",
    "        A172 (unskilled - resident)\n",
    "        A173 (skilled employee/ official)\n",
    "        A174 (management/ self-employed/ highly qualified employee/ officer)\n",
    "    ```\n",
    "\n",
    "18. Number of people being liable to provide maintenance for\n",
    "\n",
    "    ```\n",
    "        Numerical\n",
    "    ```\n",
    "\n",
    "19. Telephone\n",
    "\n",
    "    ```\n",
    "        A191 (none)\n",
    "        A192 (yes, registered under the customers name)\n",
    "    ```\n",
    "\n",
    "20. foreign worker\n",
    "\n",
    "    ```\n",
    "        A201 (yes)\n",
    "        A202 (no)\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
